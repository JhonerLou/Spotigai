{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Clean Initialization ---\n",
    "load_dotenv()\n",
    "client_id = os.getenv(\"SPOTIPY_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"SPOTIPY_CLIENT_SECRET\")\n",
    "\n",
    "# Initialize the spotipy object\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
    "\n",
    "# --- Test the connection ---\n",
    "try:\n",
    "    track = sp.track('3n3Ppam7vgaVa1iaRUc9Lp')\n",
    "    print(\"üöÄ SUCCESS! Spotify connection is working inside the notebook.\")\n",
    "    print(f\"   -> Fetched: {track['name']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå FAILED: Still an issue within the notebook environment.\")\n",
    "    print(f\"   -> Error: {e}\")\n",
    "\n",
    "# You can now use the 'sp' object in the rest of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This will list all files and folders in the directory your notebook is running from\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_famous_tracks(input_csv_path, output_csv_path, popularity_threshold=43):\n",
    "    \"\"\"\n",
    "    Reads a CSV file containing Spotify track data, filters it to keep only\n",
    "    tracks with popularity above a certain threshold, and saves the result.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file.\n",
    "        output_csv_path (str): Path where the filtered CSV file will be saved.\n",
    "        popularity_threshold (int): The minimum popularity score (0-100) \n",
    "                                     for a track to be considered \"famous\". \n",
    "                                     Defaults to 70.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from '{input_csv_path}'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERROR: Input file not found at '{input_csv_path}'.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: Could not read the CSV file. {e}\")\n",
    "        return\n",
    "\n",
    "    # Check if the 'popularity' column exists\n",
    "    if 'popularity' not in df.columns:\n",
    "        print(\"‚ùå ERROR: The input CSV file does not contain a 'popularity' column.\")\n",
    "        return\n",
    "        \n",
    "    # Ensure popularity is numeric, handling potential errors\n",
    "    df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')\n",
    "    original_count = len(df)\n",
    "    df = df.dropna(subset=['popularity']) # Remove rows where popularity couldn't be converted\n",
    "    \n",
    "    print(f\"Filtering tracks with popularity >= {popularity_threshold}...\")\n",
    "    famous_tracks_df = df[df['popularity'] >= popularity_threshold]\n",
    "    \n",
    "    filtered_count = len(famous_tracks_df)\n",
    "    \n",
    "    if filtered_count > 0:\n",
    "        print(f\"Found {filtered_count} famous tracks (out of {original_count} total).\")\n",
    "        try:\n",
    "            famous_tracks_df.to_csv(output_csv_path, index=False)\n",
    "            print(f\"‚úÖ Famous tracks saved successfully to '{output_csv_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR: Could not save the filtered CSV file. {e}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No tracks met the popularity threshold.\")\n",
    "\n",
    "# --- Define file paths and threshold ---\n",
    "input_file = 'spotify_tracks_distinct_2021_2025.csv'\n",
    "output_file = 'famous_spotify_tracks_2021_2025.csv'\n",
    "popularity_level = 43 # Adjust this threshold if you want (e.g., 60 for more songs, 80 for very famous)\n",
    "\n",
    "# --- Run the filtering function ---\n",
    "filter_famous_tracks(input_file, output_file, popularity_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_favorite_genre_and_popularity(input_csv_path, output_csv_path, popularity_threshold=70):\n",
    "    \"\"\"\n",
    "    Reads a CSV file containing Spotify track data, finds the genre with the\n",
    "    highest average popularity, filters tracks by that genre and a popularity \n",
    "    threshold, removes the genre column, and saves the result.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file.\n",
    "        output_csv_path (str): Path where the filtered CSV file will be saved.\n",
    "        popularity_threshold (int): The minimum popularity score (0-100) \n",
    "                                     for a track to be kept after genre filtering. \n",
    "                                     Defaults to 70.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from '{input_csv_path}'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERROR: Input file not found at '{input_csv_path}'.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: Could not read the CSV file. {e}\")\n",
    "        return\n",
    "\n",
    "    # Check required columns exist\n",
    "    required_cols = ['popularity', 'genre']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"‚ùå ERROR: The input CSV file must contain 'popularity' and 'genre' columns.\")\n",
    "        return\n",
    "        \n",
    "    # Ensure popularity is numeric, handling potential errors\n",
    "    df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')\n",
    "    original_count = len(df)\n",
    "    # Remove rows where popularity couldn't be converted or genre is missing\n",
    "    df = df.dropna(subset=['popularity', 'genre']) \n",
    "    valid_count = len(df)\n",
    "    print(f\"Processing {valid_count} valid rows (out of {original_count} total).\")\n",
    "\n",
    "    # --- Find the most favorite genre based on average popularity ---\n",
    "    print(\"Calculating average popularity per genre...\")\n",
    "    genre_popularity = df.groupby('genre')['popularity'].mean()\n",
    "    \n",
    "    if genre_popularity.empty:\n",
    "        print(\"‚ùå ERROR: Could not calculate genre popularity. No valid genre data found.\")\n",
    "        return\n",
    "        \n",
    "    favorite_genre = genre_popularity.idxmax()\n",
    "    highest_avg_popularity = genre_popularity.max()\n",
    "    print(f\"Most favorite genre (highest avg popularity): '{favorite_genre}' (Avg Pop: {highest_avg_popularity:.2f})\")\n",
    "    \n",
    "    # --- Filter by the favorite genre ---\n",
    "    print(f\"Filtering tracks belonging to genre '{favorite_genre}'...\")\n",
    "    genre_filtered_df = df[df['genre'] == favorite_genre].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "    \n",
    "    genre_filtered_count = len(genre_filtered_df)\n",
    "    if genre_filtered_count == 0:\n",
    "        print(f\"‚ÑπÔ∏è No tracks found for the favorite genre '{favorite_genre}'.\")\n",
    "        return\n",
    "    print(f\"Found {genre_filtered_count} tracks in the favorite genre.\")\n",
    "\n",
    "    # --- Filter by popularity threshold ---\n",
    "    print(f\"Filtering these tracks with popularity >= {popularity_threshold}...\")\n",
    "    final_filtered_df = genre_filtered_df[genre_filtered_df['popularity'] >= popularity_threshold]\n",
    "    \n",
    "    filtered_count = len(final_filtered_df)\n",
    "    \n",
    "    if filtered_count > 0:\n",
    "        print(f\"Found {filtered_count} tracks meeting both criteria.\")\n",
    "        \n",
    "        # --- Remove the genre column ---\n",
    "        print(\"Removing the 'genre' column...\")\n",
    "        final_filtered_df = final_filtered_df.drop(columns=['genre'])\n",
    "        \n",
    "        try:\n",
    "            final_filtered_df.to_csv(output_csv_path, index=False)\n",
    "            print(f\"‚úÖ Filtered tracks saved successfully to '{output_csv_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR: Could not save the filtered CSV file. {e}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è No tracks in the favorite genre ('{favorite_genre}') met the popularity threshold >= {popularity_threshold}.\")\n",
    "\n",
    "# --- Define file paths and threshold ---\n",
    "input_file = 'spotify_tracks_distinct_2021_2025.csv'\n",
    "# Updated output file name to reflect the new logic\n",
    "output_file = 'favorite_genre_popular_tracks_no_genre.csv' \n",
    "# You can adjust this threshold for the popularity filter applied *after* genre selection\n",
    "popularity_level = 43 \n",
    "\n",
    "# --- Run the filtering function ---\n",
    "filter_favorite_genre_and_popularity(input_file, output_file, popularity_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your CSV file\n",
    "input_file = 'spotify_tracks_distinct_2021_2025.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Check if the 'genre' column exists\n",
    "    if 'genre' in df.columns:\n",
    "        # Get the unique genres and convert to a list\n",
    "        unique_genres = df['genre'].dropna().unique().tolist()\n",
    "        \n",
    "        # Sort the list alphabetically for easier reading\n",
    "        unique_genres.sort()\n",
    "        \n",
    "        print(\"Unique genres found in the dataset:\")\n",
    "        # Print each genre for better readability\n",
    "        for genre in unique_genres:\n",
    "            print(f\"- {genre}\")\n",
    "            \n",
    "        print(f\"\\nTotal unique genres: {len(unique_genres)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå ERROR: The CSV file does not contain a 'genre' column.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Input file not found at '{input_file}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR: Could not read or process the CSV file. {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_by_genres_and_popularity(input_csv_path, output_csv_path, genres_to_keep, popularity_threshold=70):\n",
    "    \"\"\"\n",
    "    Reads a CSV file containing Spotify track data, filters tracks belonging \n",
    "    to a specified list of genres and meeting a popularity threshold, \n",
    "    and saves the result including the genre column.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file.\n",
    "        output_csv_path (str): Path where the filtered CSV file will be saved.\n",
    "        genres_to_keep (list): A list of genre strings to keep.\n",
    "        popularity_threshold (int): The minimum popularity score (0-100) \n",
    "                                     for a track to be kept after genre filtering. \n",
    "                                     Defaults to 70.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from '{input_csv_path}'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERROR: Input file not found at '{input_csv_path}'.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: Could not read the CSV file. {e}\")\n",
    "        return\n",
    "\n",
    "    # Check required columns exist\n",
    "    required_cols = ['popularity', 'genre']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"‚ùå ERROR: The input CSV file must contain 'popularity' and 'genre' columns.\")\n",
    "        return\n",
    "        \n",
    "    # Ensure popularity is numeric, handling potential errors\n",
    "    df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')\n",
    "    original_count = len(df)\n",
    "    # Remove rows where popularity couldn't be converted or genre is missing\n",
    "    df = df.dropna(subset=['popularity', 'genre']) \n",
    "    valid_count = len(df)\n",
    "    print(f\"Processing {valid_count} valid rows (out of {original_count} total).\")\n",
    "\n",
    "    # --- Filter by the specified list of genres ---\n",
    "    print(f\"Filtering tracks belonging to genres: {', '.join(genres_to_keep)}...\")\n",
    "    # Keep rows where the 'genre' is in the provided list\n",
    "    genre_filtered_df = df[df['genre'].isin(genres_to_keep)].copy() # Use .copy()\n",
    "    \n",
    "    genre_filtered_count = len(genre_filtered_df)\n",
    "    if genre_filtered_count == 0:\n",
    "        print(f\"‚ÑπÔ∏è No tracks found for the specified genres.\")\n",
    "        return\n",
    "    print(f\"Found {genre_filtered_count} tracks in the specified genres.\")\n",
    "\n",
    "    # --- Filter by popularity threshold ---\n",
    "    print(f\"Filtering these tracks with popularity >= {popularity_threshold}...\")\n",
    "    final_filtered_df = genre_filtered_df[genre_filtered_df['popularity'] >= popularity_threshold]\n",
    "    \n",
    "    filtered_count = len(final_filtered_df)\n",
    "    \n",
    "    if filtered_count > 0:\n",
    "        print(f\"Found {filtered_count} tracks meeting both criteria.\")\n",
    "        \n",
    "        # --- Keep the genre column (removed the .drop() line) ---\n",
    "        print(\"Keeping the 'genre' column...\")\n",
    "        # final_filtered_df = final_filtered_df.drop(columns=['genre']) # This line was removed/commented out\n",
    "        \n",
    "        try:\n",
    "            final_filtered_df.to_csv(output_csv_path, index=False)\n",
    "            print(f\"‚úÖ Filtered tracks saved successfully to '{output_csv_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR: Could not save the filtered CSV file. {e}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è No tracks in the specified genres met the popularity threshold >= {popularity_threshold}.\")\n",
    "\n",
    "# --- Define file paths, genres, and threshold ---\n",
    "input_file = 'spotify_tracks_distinct_2021_2025.csv'\n",
    "# Updated output file name for clarity (reflecting genre is kept)\n",
    "output_file = 'selected_genres_popular_tracks_with_genre.csv' \n",
    "# List of genres to keep (Removed 'dance' and 'rock')\n",
    "selected_genres = ['pop', 'k-pop', 'electronic', 'indie']\n",
    "# Popularity threshold applied after genre selection\n",
    "popularity_level = 43 \n",
    "\n",
    "# --- Run the filtering function ---\n",
    "filter_by_genres_and_popularity(input_file, output_file, selected_genres, popularity_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spotify_tracks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\music.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpandas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Read the CSV file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mspotify_tracks.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Define the languages to keep\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m languages_to_keep \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mEnglish\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMandarin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mIndonesia\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spotify_tracks.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('spotify_tracks.csv')\n",
    "\n",
    "# Define the languages to keep\n",
    "languages_to_keep = ['English', 'Mandarin', 'Indonesia']\n",
    "\n",
    "# Filter the dataframe to keep only songs in the specified languages\n",
    "filtered_df = df[df['language'].isin(languages_to_keep)]\n",
    "\n",
    "# Save the filtered dataframe to a new CSV file\n",
    "filtered_df.to_csv('spotify_tracks_filtered.csv', index=False)\n",
    "\n",
    "print(f\"Original dataset had {len(df)} songs\")\n",
    "print(f\"Filtered dataset has {len(filtered_df)} songs\")\n",
    "print(f\"Removed {len(df) - len(filtered_df)} songs\")\n",
    "\n",
    "# Show language distribution in the filtered dataset\n",
    "print(\"\\nLanguage distribution in filtered dataset:\")\n",
    "print(filtered_df['language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'high_popularity_spotify_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\music.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m file2_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mspotifydataset.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load the two files into dataframes\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file1_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file2_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/Spotigai/music.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Combine the two dataframes into one\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'high_popularity_spotify_data.csv'"
     ]
    }
   ],
   "source": [
    "file1_path = 'high_popularity_spotify_data.csv'\n",
    "file2_path = 'spotifydataset.csv'\n",
    "\n",
    "# Load the two files into dataframes\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Combine the two dataframes into one\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Show some basic information about the combined dataframe\n",
    "combined_df_info = combined_df.info()\n",
    "\n",
    "# Display the first few rows of the combined dataset\n",
    "combined_df_head = combined_df.head()\n",
    "\n",
    "combined_df_info, combined_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3_path = 'spotify_tracks_filtered.csv'\n",
    "\n",
    "# Load the file into a dataframe\n",
    "df3 = pd.read_csv(file3_path)\n",
    "\n",
    "# Combine the previously combined dataframe with this new dataframe\n",
    "final_combined_df = pd.concat([combined_df, df3], ignore_index=True)\n",
    "\n",
    "# Show some basic information about the final combined dataframe\n",
    "final_combined_df_info = final_combined_df.info()\n",
    "\n",
    "# Display the first few rows of the final combined dataset\n",
    "final_combined_df_head = final_combined_df.head()\n",
    "\n",
    "final_combined_df_info, final_combined_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined_df_path = 'final_combined_spotify_data.csv'\n",
    "final_combined_df.to_csv(final_combined_df_path, index=False)\n",
    "\n",
    "final_combined_df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_10212\\3187199278.py:4: DtypeWarning: Columns (3,7,11,12,13,14,15,18,20,25,26,27,28,31,34,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('final_combined_spotify_data.csv')\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('random_forest_mood_model_update.joblib')  \n",
    "\n",
    "\n",
    "data = pd.read_csv('final_combined_spotify_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   energy    tempo  danceability playlist_genre  loudness  liveness  valence  \\\n",
      "0   0.592  157.969         0.521            pop    -7.777     0.122    0.535   \n",
      "1   0.507  104.978         0.747            pop   -10.171     0.117    0.438   \n",
      "2   0.808  108.548         0.554            pop    -4.169     0.159    0.372   \n",
      "3   0.910  112.966         0.670            pop    -4.070     0.304    0.786   \n",
      "4   0.783  149.027         0.777            pop    -4.477     0.355    0.939   \n",
      "\n",
      "            track_artist  time_signature  speechiness  ...  artist_url  \\\n",
      "0  Lady Gaga, Bruno Mars             3.0       0.0304  ...         NaN   \n",
      "1          Billie Eilish             4.0       0.0358  ...         NaN   \n",
      "2          Gracie Abrams             4.0       0.0368  ...         NaN   \n",
      "3      Sabrina Carpenter             4.0       0.0634  ...         NaN   \n",
      "4       ROS√â, Bruno Mars             4.0       0.2600  ...         NaN   \n",
      "\n",
      "  album_name release_date explicit year popularity artwork_url track_url  \\\n",
      "0        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "1        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "2        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "3        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "4        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "\n",
      "  language  Predicted_Mood  \n",
      "0      NaN               1  \n",
      "1      NaN               1  \n",
      "2      NaN               1  \n",
      "3      NaN               3  \n",
      "4      NaN               3  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Select the relevant features (same ones used during training)\n",
    "features_to_include = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                       'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "# Prepare the feature data (X)\n",
    "X_new = data[features_to_include]\n",
    "\n",
    "# Scale the features (same scaling as done in training)\n",
    "scaler = StandardScaler()\n",
    "X_new_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "# Make predictions on the new dataset\n",
    "predictions = model.predict(X_new_scaled)\n",
    "\n",
    "# Add the predictions (mood labels) to the original dataset\n",
    "data['Predicted_Mood'] = predictions\n",
    "\n",
    "# Save the updated dataset with predicted mood labels\n",
    "data.to_csv('predicted_mood_output_new_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the dataset with the predicted mood\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_10212\\3970143934.py:4: DtypeWarning: Columns (3,7,11,12,13,14,15,18,20,25,26,27,28,31,34,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_data = pd.read_csv('predicted_mood_output_new_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   energy    tempo  danceability playlist_genre  loudness  liveness  valence  \\\n",
      "0   0.592  157.969         0.521            pop    -7.777     0.122    0.535   \n",
      "1   0.507  104.978         0.747            pop   -10.171     0.117    0.438   \n",
      "2   0.808  108.548         0.554            pop    -4.169     0.159    0.372   \n",
      "3   0.910  112.966         0.670            pop    -4.070     0.304    0.786   \n",
      "4   0.783  149.027         0.777            pop    -4.477     0.355    0.939   \n",
      "\n",
      "            track_artist  time_signature  speechiness  ...  artist_url  \\\n",
      "0  Lady Gaga, Bruno Mars             3.0       0.0304  ...         NaN   \n",
      "1          Billie Eilish             4.0       0.0358  ...         NaN   \n",
      "2          Gracie Abrams             4.0       0.0368  ...         NaN   \n",
      "3      Sabrina Carpenter             4.0       0.0634  ...         NaN   \n",
      "4       ROS√â, Bruno Mars             4.0       0.2600  ...         NaN   \n",
      "\n",
      "  album_name release_date explicit year popularity artwork_url track_url  \\\n",
      "0        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "1        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "2        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "3        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "4        NaN          NaN      NaN  NaN        NaN         NaN       NaN   \n",
      "\n",
      "  language  Predicted_Mood  \n",
      "0      NaN           Happy  \n",
      "1      NaN           Happy  \n",
      "2      NaN           Happy  \n",
      "3      NaN       Energetic  \n",
      "4      NaN       Energetic  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with predictions (adjust the path if needed)\n",
    "new_data = pd.read_csv('predicted_mood_output_new_data.csv')\n",
    "\n",
    "# Mapping of numeric labels to mood labels\n",
    "mood_mapping = {\n",
    "    0: 'Calm',\n",
    "    1: 'Happy',\n",
    "    2: 'Sad',\n",
    "    3: 'Energetic'\n",
    "}\n",
    "\n",
    "# Convert the 'Predicted_Mood' column from numeric to mood labels\n",
    "new_data['Predicted_Mood'] = new_data['Predicted_Mood'].map(mood_mapping)\n",
    "\n",
    "# Save the updated dataset with mood labels\n",
    "new_data.to_csv('predicted_mood_with_labels.csv', index=False)\n",
    "\n",
    "# Display the first few rows to check the update\n",
    "print(new_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_10212\\3345400497.py:5: DtypeWarning: Columns (3,7,11,12,13,14,15,18,20,25,26,27,28,31,34,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df5 = pd.read_csv(file5_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 612750 entries, 0 to 612749\n",
      "Data columns (total 48 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   id                        588358 non-null  object \n",
      " 1   name                      586601 non-null  object \n",
      " 2   popularity                610064 non-null  float64\n",
      " 3   duration_ms               612750 non-null  float64\n",
      " 4   explicit                  587672 non-null  object \n",
      " 5   artists                   586672 non-null  object \n",
      " 6   id_artists                586672 non-null  object \n",
      " 7   release_date              587672 non-null  object \n",
      " 8   danceability              612750 non-null  float64\n",
      " 9   energy                    612750 non-null  float64\n",
      " 10  key                       612750 non-null  float64\n",
      " 11  loudness                  612750 non-null  float64\n",
      " 12  mode                      612750 non-null  float64\n",
      " 13  speechiness               612750 non-null  float64\n",
      " 14  acousticness              612750 non-null  float64\n",
      " 15  instrumentalness          612750 non-null  float64\n",
      " 16  liveness                  612750 non-null  float64\n",
      " 17  valence                   612750 non-null  float64\n",
      " 18  tempo                     612750 non-null  float64\n",
      " 19  time_signature            611750 non-null  float64\n",
      " 20  Mood                      586672 non-null  object \n",
      " 21  playlist_genre            1686 non-null    object \n",
      " 22  track_artist              1686 non-null    object \n",
      " 23  track_popularity          2686 non-null    float64\n",
      " 24  track_href                1686 non-null    object \n",
      " 25  uri                       1686 non-null    object \n",
      " 26  track_album_name          1685 non-null    object \n",
      " 27  playlist_name             1686 non-null    object \n",
      " 28  analysis_url              1686 non-null    object \n",
      " 29  track_id                  25078 non-null   object \n",
      " 30  track_name                26078 non-null   object \n",
      " 31  track_album_release_date  1686 non-null    object \n",
      " 32  track_album_id            1686 non-null    object \n",
      " 33  playlist_subgenre         1686 non-null    object \n",
      " 34  type                      1686 non-null    object \n",
      " 35  playlist_id               1686 non-null    object \n",
      " 36  Unnamed: 0                1000 non-null    float64\n",
      " 37  artist_name               24392 non-null   object \n",
      " 38  genres                    837 non-null     object \n",
      " 39  followers                 1000 non-null    float64\n",
      " 40  artist_popularity         1000 non-null    float64\n",
      " 41  artist_url                1000 non-null    object \n",
      " 42  album_name                24392 non-null   object \n",
      " 43  year                      23392 non-null   float64\n",
      " 44  artwork_url               23392 non-null   object \n",
      " 45  track_url                 23392 non-null   object \n",
      " 46  language                  23392 non-null   object \n",
      " 47  Predicted_Mood            26078 non-null   object \n",
      "dtypes: float64(19), object(29)\n",
      "memory usage: 224.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                        id                                 name  popularity  \\\n",
       " 0  35iwgR4jXetI318WEWsa1Q                                Carve         6.0   \n",
       " 1  021ht4sdgPcrDgSk7JTbKY  Cap√≠tulo 2.16 - Banquero Anarquista         0.0   \n",
       " 2  07A5yehtSnoedViJAZkNnc   Vivo para Quererte - Remasterizado         0.0   \n",
       " 3  08FmqUhxtyLTn6pAh6bk45        El Prisionero - Remasterizado         0.0   \n",
       " 4  08y9GfoqCWfOGsKdwojr5e                  Lady of the Evening         0.0   \n",
       " \n",
       "    duration_ms explicit              artists                  id_artists  \\\n",
       " 0     126903.0        0              ['Uli']  ['45tIt06XoI0Iio4LBEVpls']   \n",
       " 1      98200.0        0  ['Fernando Pessoa']  ['14jtPCOoNZwquk5wd9DxrY']   \n",
       " 2     181640.0        0  ['Ignacio Corsini']  ['5LiOoJbxVSAMkBS2fUm3X2']   \n",
       " 3     176907.0        0  ['Ignacio Corsini']  ['5LiOoJbxVSAMkBS2fUm3X2']   \n",
       " 4     163080.0        0      ['Dick Haymes']  ['3BiJGZsyX9sJchTqcSA7Su']   \n",
       " \n",
       "   release_date  danceability  energy  ...  genres  followers  \\\n",
       " 0   1922-02-22         0.645  0.4450  ...     NaN        NaN   \n",
       " 1   1922-06-01         0.695  0.2630  ...     NaN        NaN   \n",
       " 2   1922-03-21         0.434  0.1770  ...     NaN        NaN   \n",
       " 3   1922-03-21         0.321  0.0946  ...     NaN        NaN   \n",
       " 4         1922         0.402  0.1580  ...     NaN        NaN   \n",
       " \n",
       "    artist_popularity  artist_url  album_name  year  artwork_url  track_url  \\\n",
       " 0                NaN         NaN         NaN   NaN          NaN        NaN   \n",
       " 1                NaN         NaN         NaN   NaN          NaN        NaN   \n",
       " 2                NaN         NaN         NaN   NaN          NaN        NaN   \n",
       " 3                NaN         NaN         NaN   NaN          NaN        NaN   \n",
       " 4                NaN         NaN         NaN   NaN          NaN        NaN   \n",
       " \n",
       "    language  Predicted_Mood  \n",
       " 0       NaN             NaN  \n",
       " 1       NaN             NaN  \n",
       " 2       NaN             NaN  \n",
       " 3       NaN             NaN  \n",
       " 4       NaN             NaN  \n",
       " \n",
       " [5 rows x 48 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file4_path = 'MusicMoodFinal.csv'\n",
    "file5_path = 'predicted_mood_with_labels.csv'\n",
    "# Load the file into a dataframe\n",
    "df4 = pd.read_csv(file4_path)\n",
    "df5 = pd.read_csv(file5_path)\n",
    "# Combine the previously combined dataframe with this new dataframe\n",
    "song_df = pd.concat([df4, df5], ignore_index=True)\n",
    "\n",
    "# Show some basic information about the final combined dataframe\n",
    "song_df_info = song_df.info()\n",
    "\n",
    "# Display the first few rows of the final combined dataset\n",
    "song_df_head = song_df.head()\n",
    "\n",
    "song_df_info, song_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'full_song_list.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df_path = 'full_song_list.csv'\n",
    "song_df.to_csv(song_df_path, index=False)\n",
    "\n",
    "song_df_path\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
