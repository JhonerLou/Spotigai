{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood1 = pd.read_csv('MusicMoodFinal.csv')\n",
    "# mood2 = pd.read_csv('278k_song_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spotipy\n",
    "# from spotipy.oauth2 import SpotifyClientCredentials\n",
    "# import time\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# def fetch_tracks_by_genre_year(start_year, end_year, genres=None):\n",
    "#     \"\"\"\n",
    "#     Fetch tracks grouped by year, genre, and title - returns distinct records only\n",
    "#     \"\"\"\n",
    "#     if genres is None:\n",
    "#         genres = [\n",
    "#             'pop', 'rock', 'hip-hop', 'electronic', 'indie',\n",
    "#             'r-and-b', 'country', 'latin', 'k-pop', 'metal',\n",
    "#             'dance', 'soul', 'reggae', 'jazz', 'alternative',\n",
    "#             'folk', 'blues', 'punk', 'funk', 'trap'\n",
    "#         ]\n",
    "    \n",
    "#     tracks_set = set()  # Store unique combinations\n",
    "#     tracks_list = []\n",
    "    \n",
    "#     total_years = end_year - start_year + 1\n",
    "#     total_genres = len(genres)\n",
    "#     current = 0\n",
    "    \n",
    "#     print(f\"Fetching {total_years} years × {total_genres} genres = {total_years * total_genres} search combinations\\n\")\n",
    "    \n",
    "#     for genre in genres:\n",
    "#         for year in range(start_year, end_year + 1):\n",
    "#             current += 1\n",
    "#             print(f\"[{current}/{total_years * total_genres}] Genre: {genre:15} | Year: {year}\", end=\" | \")\n",
    "            \n",
    "#             offset = 0\n",
    "#             year_genre_count = 0\n",
    "            \n",
    "#             while offset < 2000:\n",
    "#                 try:\n",
    "#                     query = f\"genre:{genre} year:{year}\"\n",
    "#                     response = sp.search(\n",
    "#                         q=query,\n",
    "#                         type=\"track\",\n",
    "#                         limit=50,\n",
    "#                         offset=offset\n",
    "#                     )\n",
    "                    \n",
    "#                     results = response['tracks']['items']\n",
    "#                     if not results:\n",
    "#                         break\n",
    "                    \n",
    "#                     for track in results:\n",
    "#                         try:\n",
    "#                             # Extract genres from audio features\n",
    "#                             track_name = track['name']\n",
    "#                             artist_name = track['artists'][0]['name'] if track['artists'] else 'Unknown'\n",
    "#                             release_date = track['album']['release_date']\n",
    "                            \n",
    "#                             # Parse year from release date\n",
    "#                             try:\n",
    "#                                 track_year = int(release_date.split('-')[0])\n",
    "#                             except:\n",
    "#                                 track_year = year\n",
    "                            \n",
    "#                             # Create unique key: (year, genre, title)\n",
    "#                             unique_key = (track_year, genre, track_name.lower().strip())\n",
    "                            \n",
    "#                             if unique_key not in tracks_set:\n",
    "#                                 tracks_set.add(unique_key)\n",
    "#                                 tracks_list.append({\n",
    "#                                     'year': track_year,\n",
    "#                                     'title': track_name,\n",
    "#                                     'artist': artist_name,\n",
    "#                                     'genre': genre,\n",
    "#                                     'release_date': release_date,\n",
    "#                                     'track_id': track['id'],\n",
    "#                                     'popularity': track.get('popularity', 0)\n",
    "#                                 })\n",
    "#                                 year_genre_count += 1\n",
    "#                         except Exception as e:\n",
    "#                             pass\n",
    "                    \n",
    "#                     if len(results) < 50:\n",
    "#                         break\n",
    "                    \n",
    "#                     offset += 50\n",
    "#                     time.sleep(0.15)\n",
    "                    \n",
    "#                 except spotipy.exceptions.SpotifyException as e:\n",
    "#                     if e.http_status == 429:\n",
    "#                         print(\"Rate limited, waiting 30s...\", end=\"\")\n",
    "#                         time.sleep(30)\n",
    "#                     break\n",
    "#                 except Exception as e:\n",
    "#                     break\n",
    "            \n",
    "#             print(f\"Found {year_genre_count} distinct tracks\")\n",
    "    \n",
    "#     return tracks_list\n",
    "\n",
    "\n",
    "# def get_distinct_tracks(start_year, end_year, genres=None):\n",
    "#     \"\"\"\n",
    "#     Get distinct tracks by year, title, and genre\n",
    "#     \"\"\"\n",
    "#     tracks = fetch_tracks_by_genre_year(start_year, end_year, genres)\n",
    "    \n",
    "#     # Convert to DataFrame for easier manipulation\n",
    "#     df = pd.DataFrame(tracks)\n",
    "    \n",
    "#     # Select distinct by year, title, genre (keep first occurrence)\n",
    "#     df_distinct = df.drop_duplicates(subset=['year', 'title', 'genre'], keep='first')\n",
    "    \n",
    "#     # Sort by year, genre, title\n",
    "#     df_distinct = df_distinct.sort_values(['year', 'genre', 'title'])\n",
    "    \n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"DISTINCT TRACKS: {len(df_distinct)} unique (year, genre, title) combinations\")\n",
    "#     print(f\"Total records fetched: {len(df)}\")\n",
    "#     print(f\"Duplicates removed: {len(df) - len(df_distinct)}\")\n",
    "#     print(f\"{'='*80}\\n\")\n",
    "    \n",
    "#     return df_distinct\n",
    "\n",
    "\n",
    "# def display_summary(df):\n",
    "#     \"\"\"\n",
    "#     Display summary statistics\n",
    "#     \"\"\"\n",
    "#     print(\"SUMMARY BY YEAR:\")\n",
    "#     print(df.groupby('year').size())\n",
    "    \n",
    "#     print(\"\\n\\nSUMMARY BY GENRE:\")\n",
    "#     print(df.groupby('genre').size().sort_values(ascending=False))\n",
    "    \n",
    "#     print(\"\\n\\nSUMMARY BY YEAR & GENRE (Top 10):\")\n",
    "#     print(df.groupby(['year', 'genre']).size().sort_values(ascending=False).head(10))\n",
    "\n",
    "\n",
    "# # Run the fetcher\n",
    "# print(\"Starting Spotify track extraction (Distinct by Year, Genre, Title)...\\n\")\n",
    "\n",
    "# df_tracks = get_distinct_tracks(2021, 2025)\n",
    "\n",
    "# # Display summary\n",
    "# display_summary(df_tracks)\n",
    "\n",
    "# # Save to CSV\n",
    "# csv_file = 'spotify_tracks_distinct_2021_2025.csv'\n",
    "# df_tracks.to_csv(csv_file, index=False)\n",
    "# print(f\"\\n✓ Saved to {csv_file}\")\n",
    "\n",
    "# # Display sample records\n",
    "# print(f\"\\n\\nSAMPLE RECORDS (First 15):\")\n",
    "# print(\"=\"*80)\n",
    "# print(df_tracks[['year', 'title', 'artist', 'genre', 'release_date']].head(15).to_string(index=False))\n",
    "\n",
    "# # SQL-like query examples\n",
    "# print(f\"\\n\\nQUERY EXAMPLES:\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# print(\"\\n1. Tracks from 2024, Pop genre:\")\n",
    "# print(df_tracks[(df_tracks['year'] == 2024) & (df_tracks['genre'] == 'pop')][['title', 'artist', 'release_date']].head(10).to_string(index=False))\n",
    "\n",
    "# print(\"\\n2. Top 5 genres by track count (2021-2025):\")\n",
    "# print(df_tracks['genre'].value_counts().head(5))\n",
    "\n",
    "# print(\"\\n3. Most popular artists (2021-2025):\")\n",
    "# print(df_tracks['artist'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotifynew_df = pd.read_csv('spotify_tracks_distinct_2021_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotifynew_df.drop(columns=['popularity'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotifynew_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "name                71\n",
       "popularity           0\n",
       "duration_ms          0\n",
       "explicit             0\n",
       "artists              0\n",
       "id_artists           0\n",
       "release_date         0\n",
       "danceability         0\n",
       "energy               0\n",
       "key                  0\n",
       "loudness             0\n",
       "mode                 0\n",
       "speechiness          0\n",
       "acousticness         0\n",
       "instrumentalness     0\n",
       "liveness             0\n",
       "valence              0\n",
       "tempo                0\n",
       "time_signature       0\n",
       "Mood                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mood1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_mood1 = mood1.dropna(subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "name                0\n",
       "popularity          0\n",
       "duration_ms         0\n",
       "explicit            0\n",
       "artists             0\n",
       "id_artists          0\n",
       "release_date        0\n",
       "danceability        0\n",
       "energy              0\n",
       "key                 0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "acousticness        0\n",
       "instrumentalness    0\n",
       "liveness            0\n",
       "valence             0\n",
       "tempo               0\n",
       "time_signature      0\n",
       "Mood                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_mood1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mood\n",
       "0     0\n",
       "1     1\n",
       "2     2\n",
       "3     0\n",
       "4     2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mood_mapping = {\n",
    "    'Calm': 0,\n",
    "    'Happy': 1,\n",
    "    'Sad': 2,\n",
    "    'Energetic': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'Mood' column\n",
    "mood1['Mood'] = mood1['Mood'].map(mood_mapping)\n",
    "\n",
    "# Verify the transformation\n",
    "mood1[['Mood']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.174160</td>\n",
       "      <td>-0.815233</td>\n",
       "      <td>-0.214754</td>\n",
       "      <td>0.490096</td>\n",
       "      <td>-0.385182</td>\n",
       "      <td>-1.483654</td>\n",
       "      <td>-0.615393</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>1.924128</td>\n",
       "      <td>0.642528</td>\n",
       "      <td>2.362779</td>\n",
       "      <td>-0.341434</td>\n",
       "      <td>-1.650527</td>\n",
       "      <td>-0.457392</td>\n",
       "      <td>-1.845842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.500768</td>\n",
       "      <td>-1.042088</td>\n",
       "      <td>-0.214754</td>\n",
       "      <td>0.791115</td>\n",
       "      <td>-1.107625</td>\n",
       "      <td>-1.483654</td>\n",
       "      <td>-2.344110</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>4.736917</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>-0.425120</td>\n",
       "      <td>-0.357710</td>\n",
       "      <td>0.398600</td>\n",
       "      <td>-0.552876</td>\n",
       "      <td>-6.072724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.500768</td>\n",
       "      <td>-0.382618</td>\n",
       "      <td>-0.214754</td>\n",
       "      <td>-0.780204</td>\n",
       "      <td>-1.449000</td>\n",
       "      <td>-1.199517</td>\n",
       "      <td>-2.156266</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>-0.298309</td>\n",
       "      <td>1.559864</td>\n",
       "      <td>-0.343432</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.369823</td>\n",
       "      <td>0.401596</td>\n",
       "      <td>2.381040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.500768</td>\n",
       "      <td>-0.420026</td>\n",
       "      <td>-0.214754</td>\n",
       "      <td>-1.460507</td>\n",
       "      <td>-1.776084</td>\n",
       "      <td>0.505310</td>\n",
       "      <td>-3.488663</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>-0.302756</td>\n",
       "      <td>1.562730</td>\n",
       "      <td>3.014787</td>\n",
       "      <td>-0.596418</td>\n",
       "      <td>-0.602678</td>\n",
       "      <td>1.730782</td>\n",
       "      <td>-1.845842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.500768</td>\n",
       "      <td>-0.529308</td>\n",
       "      <td>-0.214754</td>\n",
       "      <td>-0.972856</td>\n",
       "      <td>-1.524420</td>\n",
       "      <td>-0.631241</td>\n",
       "      <td>-1.315289</td>\n",
       "      <td>-1.389536</td>\n",
       "      <td>-0.366127</td>\n",
       "      <td>1.545530</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>-1.382743</td>\n",
       "      <td>-0.512190</td>\n",
       "      <td>0.267599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  explicit  danceability    energy       key  \\\n",
       "0   -1.174160    -0.815233 -0.214754      0.490096 -0.385182 -1.483654   \n",
       "1   -1.500768    -1.042088 -0.214754      0.791115 -1.107625 -1.483654   \n",
       "2   -1.500768    -0.382618 -0.214754     -0.780204 -1.449000 -1.199517   \n",
       "3   -1.500768    -0.420026 -0.214754     -1.460507 -1.776084  0.505310   \n",
       "4   -1.500768    -0.529308 -0.214754     -0.972856 -1.524420 -0.631241   \n",
       "\n",
       "   loudness      mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0 -0.615393  0.719665     1.924128      0.642528          2.362779 -0.341434   \n",
       "1 -2.344110  0.719665     4.736917      0.995129         -0.425120 -0.357710   \n",
       "2 -2.156266  0.719665    -0.298309      1.559864         -0.343432 -0.010498   \n",
       "3 -3.488663  0.719665    -0.302756      1.562730          3.014787 -0.596418   \n",
       "4 -1.315289 -1.389536    -0.366127      1.545530          0.062013  0.526596   \n",
       "\n",
       "    valence     tempo  time_signature  \n",
       "0 -1.650527 -0.457392       -1.845842  \n",
       "1  0.398600 -0.552876       -6.072724  \n",
       "2 -0.369823  0.401596        2.381040  \n",
       "3 -0.602678  1.730782       -1.845842  \n",
       "4 -1.382743 -0.512190        0.267599  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "features_data = mood1.drop(columns=['Mood'])\n",
    "numeric_features_data = features_data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Scale only the numeric features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numeric_features_data)\n",
    "\n",
    "# Convert the scaled features back to a DataFrame for easier handling\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=numeric_features_data.columns)\n",
    "\n",
    "# Display the first few rows of the scaled features\n",
    "scaled_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['popularity', 'explicit', 'mode', 'key', 'time_signature','duration_ms']\n",
    "features_data = features_data.drop(columns=features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>id_artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35iwgR4jXetI318WEWsa1Q</td>\n",
       "      <td>Carve</td>\n",
       "      <td>['Uli']</td>\n",
       "      <td>['45tIt06XoI0Iio4LBEVpls']</td>\n",
       "      <td>1922-02-22</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>-13.338</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.127</td>\n",
       "      <td>104.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>021ht4sdgPcrDgSk7JTbKY</td>\n",
       "      <td>Capítulo 2.16 - Banquero Anarquista</td>\n",
       "      <td>['Fernando Pessoa']</td>\n",
       "      <td>['14jtPCOoNZwquk5wd9DxrY']</td>\n",
       "      <td>1922-06-01</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.2630</td>\n",
       "      <td>-22.136</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.655</td>\n",
       "      <td>102.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07A5yehtSnoedViJAZkNnc</td>\n",
       "      <td>Vivo para Quererte - Remasterizado</td>\n",
       "      <td>['Ignacio Corsini']</td>\n",
       "      <td>['5LiOoJbxVSAMkBS2fUm3X2']</td>\n",
       "      <td>1922-03-21</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>-21.180</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.457</td>\n",
       "      <td>130.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08FmqUhxtyLTn6pAh6bk45</td>\n",
       "      <td>El Prisionero - Remasterizado</td>\n",
       "      <td>['Ignacio Corsini']</td>\n",
       "      <td>['5LiOoJbxVSAMkBS2fUm3X2']</td>\n",
       "      <td>1922-03-21</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>-27.961</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.397</td>\n",
       "      <td>169.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08y9GfoqCWfOGsKdwojr5e</td>\n",
       "      <td>Lady of the Evening</td>\n",
       "      <td>['Dick Haymes']</td>\n",
       "      <td>['3BiJGZsyX9sJchTqcSA7Su']</td>\n",
       "      <td>1922</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>-16.900</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.196</td>\n",
       "      <td>103.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                 name  \\\n",
       "0  35iwgR4jXetI318WEWsa1Q                                Carve   \n",
       "1  021ht4sdgPcrDgSk7JTbKY  Capítulo 2.16 - Banquero Anarquista   \n",
       "2  07A5yehtSnoedViJAZkNnc   Vivo para Quererte - Remasterizado   \n",
       "3  08FmqUhxtyLTn6pAh6bk45        El Prisionero - Remasterizado   \n",
       "4  08y9GfoqCWfOGsKdwojr5e                  Lady of the Evening   \n",
       "\n",
       "               artists                  id_artists release_date  danceability  \\\n",
       "0              ['Uli']  ['45tIt06XoI0Iio4LBEVpls']   1922-02-22         0.645   \n",
       "1  ['Fernando Pessoa']  ['14jtPCOoNZwquk5wd9DxrY']   1922-06-01         0.695   \n",
       "2  ['Ignacio Corsini']  ['5LiOoJbxVSAMkBS2fUm3X2']   1922-03-21         0.434   \n",
       "3  ['Ignacio Corsini']  ['5LiOoJbxVSAMkBS2fUm3X2']   1922-03-21         0.321   \n",
       "4      ['Dick Haymes']  ['3BiJGZsyX9sJchTqcSA7Su']         1922         0.402   \n",
       "\n",
       "   energy  loudness  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0  0.4450   -13.338       0.4510         0.674            0.7440     0.151   \n",
       "1  0.2630   -22.136       0.9570         0.797            0.0000     0.148   \n",
       "2  0.1770   -21.180       0.0512         0.994            0.0218     0.212   \n",
       "3  0.0946   -27.961       0.0504         0.995            0.9180     0.104   \n",
       "4  0.1580   -16.900       0.0390         0.989            0.1300     0.311   \n",
       "\n",
       "   valence    tempo  \n",
       "0    0.127  104.851  \n",
       "1    0.655  102.009  \n",
       "2    0.457  130.418  \n",
       "3    0.397  169.980  \n",
       "4    0.196  103.220  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_data.select_dtypes(include=['float64', 'int64']))\n",
    "target = mood1['Mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      8203\n",
      "           1       0.96      0.95      0.95     30541\n",
      "           2       0.98      0.98      0.98     42417\n",
      "           3       0.97      0.97      0.97     36174\n",
      "\n",
      "    accuracy                           0.97    117335\n",
      "   macro avg       0.97      0.97      0.97    117335\n",
      "weighted avg       0.97      0.97      0.97    117335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 8061    13   129     0]\n",
      " [    4 29065   515   957]\n",
      " [  132   432 41546   307]\n",
      " [    1   838   289 35046]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\acer\\Downloads\\Spotigai\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.94051822 0.96402159 0.9638554         nan        nan\n",
      " 0.94063754        nan        nan 0.96722185]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 364, 'random_state': 42}\n",
      "Accuracy of tuned model: 0.9697\n",
      "\n",
      "Classification Report for Tuned Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      8203\n",
      "           1       0.96      0.95      0.96     30541\n",
      "           2       0.98      0.98      0.98     42417\n",
      "           3       0.97      0.97      0.97     36174\n",
      "\n",
      "    accuracy                           0.97    117335\n",
      "   macro avg       0.97      0.97      0.97    117335\n",
      "weighted avg       0.97      0.97      0.97    117335\n",
      "\n",
      "\n",
      "Confusion Matrix for Tuned Model:\n",
      "[[ 8050    13   139     1]\n",
      " [    6 29065   530   940]\n",
      " [  125   429 41545   318]\n",
      " [    1   781   278 35114]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distribution for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),  # Random number of trees between 100 and 500\n",
    "    'max_depth': [None, 10, 20, 30, 40],  # Max depth of the trees\n",
    "    'min_samples_split': randint(2, 10),  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 10),  # Minimum samples required at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at each split\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=10, cv=3, n_jobs=-1, verbose=2, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "\n",
    "# Best model from random search\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_best = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Accuracy of tuned model: {accuracy_best:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report for Tuned Model:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# Confusion Matrix for the tuned model\n",
    "print(\"\\nConfusion Matrix for Tuned Model:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully to random_forest_mood_model_update.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# The model you trained with RandomizedSearchCV\n",
    "model_to_save = best_rf_model \n",
    "filename = 'random_forest_mood_model_update.joblib'\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model_to_save, filename)\n",
    "\n",
    "print(f\"✅ Model saved successfully to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
